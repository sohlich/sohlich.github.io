<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Post-rsses on Radomir Sohlich</title>
    <link>https://sohlich.github.io/post/index.xml</link>
    <description>Recent content in Post-rsses on Radomir Sohlich</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>© 2017 Radomir Sohlich</copyright>
    <lastBuildDate>Mon, 18 Sep 2017 18:32:54 +0200</lastBuildDate>
    <atom:link href="https://sohlich.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Golang: Don’t afraid of makefiles</title>
      <link>https://sohlich.github.io/post/go_makefile/</link>
      <pubDate>Mon, 18 Sep 2017 18:32:54 +0200</pubDate>
      
      <guid>https://sohlich.github.io/post/go_makefile/</guid>
      <description>

&lt;p&gt;I&amp;rsquo;m using Golang for a while. During the development, I was used to repeatedly execute &amp;ldquo;go build&amp;rdquo;,&amp;ldquo;go test&amp;rdquo; manually. This was a bad habit on which I resign. It is not so painful if you use simple command without any args. But in case of more complex tasks, naturally, it is going to be a pain. There are few options you can consider as a way out. You can use a bash script to do the work for you. Or better, at least for me, you can write a makefile. The make tool is there for this reason and in the makefile you can keep all your common tasks together. I&amp;rsquo;m not &amp;ldquo;make tool guru&amp;rdquo; to be able to educate how to write the proper one, but in this post, I put together the makefile which works for most of my projects. Let&amp;rsquo;s go through it.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    # Go parameters
    GOCMD=go
    GOBUILD=$(GOCMD) build
    GOCLEAN=$(GOCMD) clean
    GOTEST=$(GOCMD) test
    GOGET=$(GOCMD) get
    BINARY_NAME=mybinary
    BINARY_UNIX=$(BINARY_NAME)_unix
    
    all: test build
    build: 
            $(GOBUILD) -o $(BINARY_NAME) -v
    test: 
            $(GOTEST) -v ./...
    clean: 
            $(GOCLEAN)
            rm -f $(BINARY_NAME)
            rm -f $(BINARY_UNIX)
    run:
            $(GOBUILD) -o $(BINARY_NAME) -v ./...
            ./$(BINARY_NAME)
    deps:
            $(GOGET) github.com/markbates/goth
            $(GOGET) github.com/markbates/pop
    
    
    # Cross compilation
    build-linux:
            CGO_ENABLED=0 GOOS=linux GOARCH=amd64 $(GOBUILD) -o $(BINARY_UNIX) -v
    docker-build:
            docker run --rm -it -v &amp;quot;$(GOPATH)&amp;quot;:/go -w /go/src/bitbucket.org/rsohlich/makepost golang:latest go build -o &amp;quot;$(BINARY_UNIX)&amp;quot; -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s say I like to keep the idea of the DRY rule. So it is handy to declare commonly used commands and variables at the top of the file. And refer to them further in the file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# Basic go commands
GOCMD=go
GOBUILD=$(GOCMD) build
GOCLEAN=$(GOCMD) clean
GOTEST=$(GOCMD) test
GOGET=$(GOCMD) get

# Binary names
BINARY_NAME=mybinary
BINARY_UNIX=$(BINARY_NAME)_unix
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The makefile targets are defined bellow labels like “&lt;name&gt;:”. These are executed by make tool if the parameter for make is given. If no parameter is provided to make tool, the first task is executed. In this case the “all” task is executed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; make run // call specific task
&amp;gt; make // make tool calls &amp;quot;all&amp;quot; task
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;basic-commands&#34;&gt;Basic commands&lt;/h2&gt;

&lt;p&gt;One of the essential parts of the makefile is the build step. Using the variable $(GOBUILD) the “go build” command is executed. The binary name is defined by “-o $(BINARY_NAME)” and I found useful to switch to the verbose mode with “-v”. With verbose mode, you can see the currently built packages.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;build:
  $(GOBUILD) -o $(BINARY_NAME) -v // expands to: &amp;quot;go build -o mybinary -v&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Just because a lot of us are just lazy, the “run” target is here. The target builds the binary and executes the application consequently.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;run:
        $(GOBUILD) -o $(BINARY_NAME) -v ./...
        ./$(BINARY_NAME)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Naturally, the test command should be the part of the project makefile. I personally always choose the verbose mode to be able to debug and watch the test run better.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;test:
  $(GOTEST) -v ./...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the project uses CI/CD or just for consistency, it is good to keep the list of dependencies used in packages. This is done by the “deps” task, which should get all the necessary dependencies by “go get” command.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;deps:
        $(GOGET) github.com/markbates/goth
        $(GOGET) github.com/markbates/pop
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To wrap up this section of useful commands, the clean command is accommodated into makefile. The “rm -f” command is added to remove binary with the custom name in $(BINARY_XXX) variable. Typically another clean-up command could be part of this make section.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;clean: 
        $(GOCLEAN)
        rm -f $(BINARY_NAME)
        rm -f $(BINARY_UNIX)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;crosscompilation-commands&#34;&gt;Crosscompilation commands&lt;/h2&gt;

&lt;p&gt;If the project is intended to run on another platform than the one where it is developed, it is useful to include cross compilation commands to make file. I usually run the binaries on
Linux platform in the container, so the makefile contains the Linux build.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;build-linux:
        CGO_ENABLED=0 GOOS=linux GOARCH=amd64 $(GOBUILD) -o $(BINARY_UNIX) -v
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If your code use C binding you could get stuck a little bit. The issue with CGO is that you need a gcc compatible for given platform. So if the development is done on OSX/Windows you need to build gcc to be able to compile for Linux. At least for me, the configuration of gcc to cross compile the C code is not so straightforward on OSX. If the CGO is needed, the docker image is the best way how to create Linux build. The only requirement: Docker has to be installed.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker-build:
        docker run --rm -it -v &amp;quot;$(GOPATH)&amp;quot;:/go -w /go/src/bitbucket.org/rsohlich/makepost golang:latest go build -o &amp;quot;$(BINARY_UNIX)&amp;quot; -v
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;This way you can make your go development process more effective and fluent. The makefile used in this post is available &lt;a href=&#34;https://gist.github.com/sohlich/8432e7c1bd56bc395b101d1ba444e982&#34;&gt;here&lt;/a&gt;. Don’t hesitate to comment or ask questions, I’ll be happy to answer or talk about this. Enjoy!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Deploy on Clever Cloud with Bitbucket Pipelines</title>
      <link>https://sohlich.github.io/post/clever_cloud_pipelines/</link>
      <pubDate>Thu, 31 Aug 2017 05:08:10 +0200</pubDate>
      
      <guid>https://sohlich.github.io/post/clever_cloud_pipelines/</guid>
      <description>

&lt;p&gt;There are a lot of CI tools that are available on the market. These are usualy free for open-source project. Recently I’ve come across the &lt;a href=&#34;https://bitbucket.org/product/features/pipelines&#34;&gt;Bitbucket Pipelines&lt;/a&gt; feature that is free also for private ones, with limitation naturally. It is the CI/CD tool bounded to Bitbucket repository, that is based on containers.
In this post, I’d like to walk through the setup of Pipelines to deploy the build on &lt;a href=&#34;https://www.clever-cloud.com&#34;&gt;Clever Cloud&lt;/a&gt;. The Clever Cloud is PaaS provider, which I have been using for about 2 years. They come up with a lot of platforms, but the best one and my favorite is the Docker. With this one, it is possible to deploy any Docker image.
For this post, I’ve chosen the Go application to be deployed on top of the Docker platform, but the same approach could be used with other languages.&lt;/p&gt;

&lt;h2 id=&#34;repository-content&#34;&gt;Repository content&lt;/h2&gt;

&lt;p&gt;First, we need to add a Dockerfile to application folder (for the simplicity). The most simple Dockerfile could look like following one.&lt;/p&gt;

&lt;p&gt;${PROJECT_FOLDER}/Dockerfile&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    FROM golang:latest
    #copy the binary of app
    COPY linux_bin linux_bin
    EXPOSE 8080
    #execute the binary
    ENTRYPOINT [&amp;quot;./linux_bin&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The important step in Dockerfile is the exposing of port 8080. The Clever Cloud requires this port as a default HTTP port. If the application does not respond on this port, the monitor tool evaluates the application as non-working and the deployment fails.&lt;/p&gt;

&lt;p&gt;The binary itself will be built during the Pipelines run. We can test the Dockerfile by building the binary. As we are running the binary within the container, it must be compiled for Linux and amd64 architecture.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt; GOOS=linux GOARCH=AMD64 go build -o linux_bin -v
    &amp;gt; docker build --rm -t clever_cloud_deploy .
    Sending build context to Docker daemon  42.55MB
    Step 1/4 : FROM golang:alpine
    Step 2/4 : COPY linux_bin linux_bin
    Step 3/4 : EXPOSE 8080
    Step 4/4 : CMD ./linux_bin
    Successfully built 692db10e1840
    Successfully tagged clever_cloud_deploy:latest
    &amp;gt; docker run --rm -it clever_cloud_deploy:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So the Dockerfile is OK. Now the Pipelines config file must be created. The easiest way how to do that is to copy the config from bitbucket docs and modify it to fit your needs. (&lt;a href=&#34;https://confluence.atlassian.com/bitbucket/language-guides-856821477.html&#34;&gt;Bitbucket Docs&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;${PROJECT_FOLDER}/bitbucket-pipelines.yml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    image: golang:latest
    pipelines:
      default:
        - step:
            caches:
              - gocache        # custom golang cache
            script: # Modify the commands below to build your repository.
              - PACKAGE_PATH=&amp;quot;${GOPATH}/src/bitbucket.org/${BITBUCKET_REPO_OWNER}/${BITBUCKET_REPO_SLUG}&amp;quot;
              - mkdir -pv &amp;quot;${PACKAGE_PATH}&amp;quot;
              - tar -cO --exclude-vcs --exclude=bitbucket-pipelines.yml . | tar -xv -C &amp;quot;${PACKAGE_PATH}&amp;quot;
              - cd &amp;quot;${PACKAGE_PATH}&amp;quot;
              - go get -v
              - go build -o linux_bin -v
              - go test -v

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;deployment-to-clever-cloud&#34;&gt;Deployment to Clever Cloud&lt;/h2&gt;

&lt;p&gt;The deployment of an application to Clever Cloud is done via push to the git repository. The push to the master branch invokes the deployment on the provider side. The Docker platform was chosen so the Dockerfile must be the essential part of pushed changes.  Naturally, all the files used in Dockerfile are needed. The deployment on the provider side, in fact, consists of the Docker file build and start of the container based on the created docker image.&lt;/p&gt;

&lt;h3 id=&#34;ssh-keys&#34;&gt;SSH Keys&lt;/h3&gt;

&lt;p&gt;To be able to push into the Clever Cloud repository, the SSH public key must be provided. The existing key could be added or you can generate a new one in Bitbucket repository (Settings → Pipelines → SSHKeys) and configure it to be allowed to use in Clever Cloud (see Clever Cloud settings).&lt;/p&gt;

&lt;h3 id=&#34;clever-cloud-repository-and-config&#34;&gt;Clever Cloud repository and config&lt;/h3&gt;

&lt;p&gt;Each application in Clever Cloud has so called “deployment URL” defined in information tab in the Clever Cloud console (administration page). The URL is similar to one below.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    git+ssh://git@push-par-clevercloud-customers.services.clever-cloud.com/app_b5a2def7-ed24-4fde-bcf2-5d0525c2d00b.git
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This URL would be used in Pipelines config file as a remote git repository to push the built files. The deploy than will consist of these steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;initialize Git repository&lt;/li&gt;
&lt;li&gt;commit all files needed for Dockerfile build&lt;/li&gt;
&lt;li&gt;push to remote master branch&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Before we do that we need to add the push-par-clevercloud-customers.services.clever-cloud.com host to “known hosts”. This is done via Settings → SSH → Known Hosts section.
After this is done the steps described above can be added to Pipelines config file.&lt;/p&gt;

&lt;p&gt;${PROJECT_FOLDER}/bitbucket-pipelines.yml (partial)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;              - git init
              - git config user.name &amp;quot;Pipeline&amp;quot; &amp;amp;&amp;amp; git config user.email &amp;quot;pipeline@example.org&amp;quot;
              # Use -f switch to override .gitignore file
              - git add -f linux_bin 
              - git commit -m &amp;quot;init&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Initialisation of the repository, configuration of user and email is needed. Without this git refuses to work properly.&lt;/p&gt;

&lt;p&gt;Finally, push all the changes to Clever Cloud repo using the —force switch.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    git push git+ssh://git@push-par-clevercloud-customers.services.clever-cloud.com/app_b5a2def7-ed24-4fde-bcf2-5d0525c2d00b.git master --force
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The complete Pipelines configuration file could look like this.&lt;/p&gt;

&lt;p&gt;${PROJECT_FOLDER}/bitbucket-pipelines.yml&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    image: golang:latest
    pipelines:
      default:
        - step:
            caches:
              - gocache        # custom golang cache
              - xchache        # custom golang cache
              - pkgincache        # custom golang cache
            script: # Modify the commands below to build your repository.
              - PACKAGE_PATH=&amp;quot;${GOPATH}/src/bitbucket.org/${BITBUCKET_REPO_OWNER}/${BITBUCKET_REPO_SLUG}&amp;quot;
              - mkdir -pv &amp;quot;${PACKAGE_PATH}&amp;quot;
              - tar -cO --exclude-vcs --exclude=bitbucket-pipelines.yml . | tar -xv -C &amp;quot;${PACKAGE_PATH}&amp;quot;
              - cd &amp;quot;${PACKAGE_PATH}&amp;quot;
              - go get -v
              - go build -o linux_bin -v
              - go test -v
              - git init
              # Deployment to clever cloud
              - git config user.name &amp;quot;Pipeline&amp;quot; &amp;amp;&amp;amp; git config user.email &amp;quot;pipeline@example.org&amp;quot;
              - git add -f linux_bin
              - git commit -m &amp;quot;init&amp;quot;
              - git push git+ssh://git@push-par-clevercloud-customers.services.clever-cloud.com/app_b5a2def7-ed24-4fde-bcf2-5d0525c2d00b.git master --force
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That’s it. After your commit arrive to Bitbucket repository the Pipelines run is started, subsequently the build deployed on Clever Cloud. Enjoy!&lt;/p&gt;

&lt;p&gt;Link to the sample repository:
&lt;a href=&#34;https://bitbucket.org/rsohlich/clever_cloud_deploy&#34;&gt;https://bitbucket.org/rsohlich/clever_cloud_deploy&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Angular on Electron, part 2</title>
      <link>https://sohlich.github.io/post/angular_electron_2/</link>
      <pubDate>Sun, 20 Aug 2017 20:33:51 +0200</pubDate>
      
      <guid>https://sohlich.github.io/post/angular_electron_2/</guid>
      <description>

&lt;p&gt;In the previous post the bootstrap of Angular project on Electron platform was described. In this one, the process of application packaging will be presented.&lt;/p&gt;

&lt;p&gt;One of the benefits of Electron is that it runs on all major platforms. Each platform has naturally its needs regarding to creating the distribution package. Fortunately, the packaging and all that stuff do not need to be done manually. There are few tools which will help you. But first things first.&lt;/p&gt;

&lt;h2 id=&#34;get-ready&#34;&gt;Get ready&lt;/h2&gt;

&lt;p&gt;Before we begin this tutorial there will be one small change to an existing project from part 1. Because the folder &amp;ldquo;dist&amp;rdquo; will be used for another purpose, the Angular default build folder will be changed to &amp;ldquo;build&amp;rdquo;. This is done by modification of &amp;ldquo;angular-cli.json&amp;rdquo; config file. The property &amp;ldquo;outDir&amp;rdquo; of &amp;ldquo;apps&amp;rdquo; section will change the default output directory.&lt;/p&gt;

&lt;p&gt;${PROJECT_FOLDER}/angular-cli.json:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;quot;apps&amp;quot;: [
        {
          ...
          &amp;quot;root&amp;quot;: &amp;quot;src&amp;quot;,
          &amp;quot;outDir&amp;quot;: &amp;quot;build&amp;quot;
          ...}
          ],
      ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After this change, test the configuration by building the project. The folder &amp;ldquo;build&amp;rdquo; should be created with all the content. If everything is OK, we are good to go.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt; ng build
    &amp;gt; tree build/
    build/
        ├── favicon.ico
        ├── index.html
        ├── inline.bundle.js
        ├── inline.bundle.js.map
        ├── main.bundle.js
        ├── main.bundle.js.map
        ├── polyfills.bundle.js
        ├── polyfills.bundle.js.map
        ├── styles.bundle.js
        ├── styles.bundle.js.map
        ├── vendor.bundle.js
        └── vendor.bundle.js.map
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;assets-packaging&#34;&gt;Assets packaging&lt;/h2&gt;

&lt;p&gt;All the assets of application need to be bundled in the distribution somehow. Naturally there are several ways how to accomplish that. The first option is to bundle the files ( js, css bundles) as they are. Your install folder that will contain the build folder with all the files.  Sometimes it is better to hide the raw files from user. So the next option is to use archive. As this si preferred way, the asar archive were designed.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Asar archive&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The asar archive (&lt;a href=&#34;https://github.com/electron/asar&#34;&gt;https://github.com/electron/asar&lt;/a&gt;) is tar-like format very easy to use. Following example demonstrates the basic usage.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt; npm install -g asar
    &amp;gt; asar pack app app.asar
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The benefit of asar archive is that it could be read as simple as a folder in the filesystem. One way how to achieve it is via Node API. (&lt;a href=&#34;https://electron.atom.io/docs/tutorial/application-packaging/#using-asar-archives&#34;&gt;https://electron.atom.io/docs/tutorial/application-packaging/#using-asar-archives&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    const fs = require(&#39;fs&#39;)
    fs.readdirSync(&#39;/path/to/example.asar&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is more. The Electron BrowserWindow class provides the ability to access the archive too. So it can load the &amp;ldquo;index.html&amp;rdquo; file in the application the common way via the BrowserWindow#loadURL method. In this case, the &amp;ldquo;__dirname&amp;rdquo; would be the path to the .asar file.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        var path = require(&#39;path&#39;);
        var url = require(&#39;url&#39;);
        win = new BrowserWindow({ width: 1280, height: 960 });
        // __dirname is a current working directory
        win.loadURL(url.format({
                pathname: path.join(__dirname, &#39;build&#39;, &#39;index.html&#39;),
                protocol: &#39;file:&#39;,
                slashes: true
        }));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now after the packaging and the ways how to use the asar were described, let&amp;rsquo;s move to an installer. Don&amp;rsquo;t worry you would not need to create the archives and config files manually. The tools for this purpose are there for you.&lt;/p&gt;

&lt;h2 id=&#34;electron-builder&#34;&gt;Electron builder&lt;/h2&gt;

&lt;p&gt;For this tutorial, the &lt;a href=&#34;https://github.com/electron-userland/electron-builder&#34;&gt;electron-builder&lt;/a&gt; tool will be used.  The utility simplifies the creation of distribution package for all major platforms, even the cross platform build is possible.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    npm install electron-builder --save-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The electron-builder tool needs a little bit of configuration, so the final changes in &amp;ldquo;package.json&amp;rdquo; file looks like this (This is a minimal configuration)
${PROJECT_FOLDER}/package.json&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      &amp;quot;author&amp;quot;: {
        &amp;quot;name&amp;quot;: &amp;quot;Radomir Sohlich&amp;quot;,
        &amp;quot;email&amp;quot;: &amp;quot;sohlich@example.com&amp;quot;
      },
      &amp;quot;description&amp;quot;: &amp;quot;Example application.&amp;quot;,
      &amp;quot;devDependencies&amp;quot;: {
         &amp;quot;electron-builder&amp;quot;: &amp;quot;^19.22.0&amp;quot;,
      },
      &amp;quot;build&amp;quot;: {
        &amp;quot;appId&amp;quot;: &amp;quot;com.example.app&amp;quot;,
        &amp;quot;files&amp;quot;: [
          &amp;quot;main.js&amp;quot;,
          &amp;quot;build&amp;quot;
        ],
        &amp;quot;mac&amp;quot;: {
          &amp;quot;category&amp;quot;: &amp;quot;productivity&amp;quot;
        }
      }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The build-&amp;gt;files section defines which files/folders will be included in asar archive. The archive works as the application folder. The electron executes the main.js directly from the archive. The build folder contains application build with index.html and bundles. The &amp;ldquo;author&amp;rdquo; and &amp;ldquo;description&amp;rdquo; properties are not mandatory, but it is always better to provide this info. (The electron-builder will produce less warning messages :) )&lt;/p&gt;

&lt;p&gt;The final step is to add a npm command to run the electron-builder build.&lt;/p&gt;

&lt;p&gt;${PROJECT_FOLDER}/package.json&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;quot;scripts&amp;quot;: {
        &amp;quot;dist&amp;quot;: &amp;quot;build --mac&amp;quot;
      },
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &amp;ldquo;dist&amp;rdquo; command will build the application and subsequently build a distribution package. In this case, the MacOS is configured. The platform is defined by the switch. The available values are in the following figure. (stolen from project documentation &lt;a href=&#34;https://github.com/electron-userland/electron-builder#cli-usage&#34;&gt;https://github.com/electron-userland/electron-builder#cli-usage&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      --mac, -m, -o, --macos   Build for macOS, accepts target list (see
                               https://goo.gl/HAnnq8).                       [array]
      --linux, -l              Build for Linux, accepts target list (see
                               https://goo.gl/O80IL2)                        [array]
      --win, -w, --windows     Build for Windows, accepts target list (see
                               https://goo.gl/dL4i8i)                        [array]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To execute the build, call the command in terminal and the output should look like this.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt; npm run dist
    &amp;gt; electron_app@0.0.0 distmac /Users/radek/Junk/electron_app
    &amp;gt; ng build &amp;amp;&amp;amp; build --mac
    
    Hash: ee6c31ccdab8735b740c
    Time: 10199ms
    chunk    {0} polyfills.bundle.js, polyfills.bundle.js.map (polyfills) 177 kB {4} [initial] [rendered]
    chunk    {1} main.bundle.js, main.bundle.js.map (main) 5.27 kB {3} [initial] [rendered]
    chunk    {2} styles.bundle.js, styles.bundle.js.map (styles) 10.5 kB {4} [initial] [rendered]
    chunk    {3} vendor.bundle.js, vendor.bundle.js.map (vendor) 1.89 MB [initial] [rendered]
    chunk    {4} inline.bundle.js, inline.bundle.js.map (inline) 0 bytes [entry] [rendered]
    electron-builder 19.22.1
    No native production dependencies
    Packaging for darwin x64 using electron 1.7.5 to dist/mac
    Building macOS zip
    Building DMG
    Application icon is not set, default Electron icon will be used
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After the successful command run, the dist folder should be created in the working directory and the installer should be there.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    dist/
    --- electron_app-0.0.0-mac.zip
    --- electron_app-0.0.0.dmg
    --- mac
        --- electron_app.app
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &amp;ldquo;electron_app.app/Resources&amp;rdquo; folder contains the asar archive with &amp;ldquo;app.asar&amp;rdquo; file. That is our bundled application. If you need to debug, what is packed into &amp;ldquo;app.asar&amp;rdquo; file and what is included in the installer. The &amp;ldquo;build &amp;ndash;dir&amp;rdquo; command could be used. It will create only the expanded distribution folder (same as dist/mac).&lt;/p&gt;

&lt;p&gt;Note:
If you encounter the error by executing the &amp;ldquo;build &amp;ndash;dir&amp;rdquo; command.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    Error: Cannot find electron dependency to get electron version
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The electron dependency need to be add to project.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    npm install electron --save-dev
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The repository with example project &lt;a href=&#34;https://github.com/sohlich/angular_on_electron&#34;&gt;https://github.com/sohlich/angular_on_electron&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;series&#34;&gt;Series:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://sohlich.github.io/post/angular_electron/&#34;&gt;Angular on Electron, part 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sohlich.github.io/post/angular_electron_2/&#34;&gt;Angular on Electron, part 2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Angular on Electron, part 1</title>
      <link>https://sohlich.github.io/post/angular_electron/</link>
      <pubDate>Sat, 29 Jul 2017 08:48:41 +0200</pubDate>
      
      <guid>https://sohlich.github.io/post/angular_electron/</guid>
      <description>

&lt;p&gt;Today it is possible to have almost all the applications as a service online. Literally you don&amp;rsquo;t have to install any of it on you computer. Even if this is possible, but for me it is still more comfortable to have a dedicated desktop application. I believe I&amp;rsquo;m not the only one. There are a lot of ways how to create a desktop application. Utilizing the native frameworks like Qt, WxWidgets is always an option. For Java people, there are two useful options: swing and java fx.
But for me as web developer, though java based, it means to learn a new library or whole framework, all its features and pitfalls&amp;hellip; But what If anybody tells you that you can use your good &amp;ldquo;old&amp;rdquo; javascript and HTML? Me, I’m totally IN.&lt;/p&gt;

&lt;p&gt;So here comes the Electron platform (&lt;a href=&#34;https://electron.atom.io/&#34;&gt;https://electron.atom.io/&lt;/a&gt;) based on Chromium browser. It provides presentation layer and runtime for your application.
The Electron accompanied by Angular framework is a very solid foundation for desktop application development in most of use cases. By the way lot of well known applications are based on electron: VS Code, Slack, WhatsApp&amp;hellip;&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ll try to show you how to start your own project, or &amp;ldquo;Electronify&amp;rdquo; the existing one.&lt;/p&gt;

&lt;h1 id=&#34;bootstrap-your-project&#34;&gt;Bootstrap your project&lt;/h1&gt;

&lt;p&gt;Using an Angular CLI generate a new application and test the first run. After following command you should be able to see the result in the browser on URL &lt;a href=&#34;http://localhost:4200&#34;&gt;http://localhost:4200&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;gt; ng new electron_app
&amp;gt; ng serve
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Add main file for the electron called main.js&lt;/p&gt;

&lt;p&gt;${PROJECT_FOLDER}/main.js:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    const { app, BrowserWindow } = require(&#39;electron&#39;);
    
    // Executes when the application 
    // is initialized.
    app.on(&#39;ready&#39;, function() {
        console.log(&#39;Starting application!&#39;);
        // Create browser window 
        // with given parameters
        mainWindow = new BrowserWindow({ width: 1280, height: 960 });
        mainWindow.loadURL(&amp;quot;http://localhost:4200&amp;quot;);
    
        // It is useful to open dev tools
        // for debug.
        mainWindow.webContents.openDevTools();
        mainWindow.on(&#39;closed&#39;, function() {
            mainWindow = null;
        });
    });
    
    // Defines the behavior on close.
    app.on(&#39;window-all-closed&#39;, function() {
        app.quit();
    });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And update the package.json file by few additional properties:
${PROJECT_FOLDER}/package.json:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    {
        &amp;quot;name&amp;quot;: &amp;quot;electron_app&amp;quot;,
        &amp;quot;version&amp;quot;: &amp;quot;0.0.0&amp;quot;,
        &amp;quot;main&amp;quot;: &amp;quot;main.js&amp;quot;,
        &amp;quot;license&amp;quot;: &amp;quot;MIT&amp;quot;,
        &amp;quot;scripts&amp;quot;: {
            &amp;quot;ng&amp;quot;: &amp;quot;ng&amp;quot;,
            &amp;quot;start&amp;quot;: &amp;quot;ng serve&amp;quot;,
            &amp;quot;build&amp;quot;: &amp;quot;ng build&amp;quot;,
            &amp;quot;test&amp;quot;: &amp;quot;ng test&amp;quot;,
            &amp;quot;lint&amp;quot;: &amp;quot;ng lint&amp;quot;,
            &amp;quot;e2e&amp;quot;: &amp;quot;ng e2e&amp;quot;
        },
        &amp;quot;private&amp;quot;: true,
        &amp;quot;dependencies&amp;quot;: {
            &amp;quot;@angular/animations&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@angular/common&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@angular/compiler&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@angular/core&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@angular/forms&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@angular/http&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@angular/platform-browser&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@angular/platform-browser-dynamic&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@angular/router&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;core-js&amp;quot;: &amp;quot;^2.4.1&amp;quot;,
            &amp;quot;rxjs&amp;quot;: &amp;quot;^5.4.1&amp;quot;,
            &amp;quot;zone.js&amp;quot;: &amp;quot;^0.8.14&amp;quot;
        },
        &amp;quot;devDependencies&amp;quot;: {
            &amp;quot;@angular/cli&amp;quot;: &amp;quot;1.2.4&amp;quot;,
            &amp;quot;@angular/compiler-cli&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@angular/language-service&amp;quot;: &amp;quot;^4.0.0&amp;quot;,
            &amp;quot;@types/jasmine&amp;quot;: &amp;quot;~2.5.53&amp;quot;,
            &amp;quot;@types/jasminewd2&amp;quot;: &amp;quot;~2.0.2&amp;quot;,
            &amp;quot;@types/node&amp;quot;: &amp;quot;~6.0.60&amp;quot;,
            &amp;quot;codelyzer&amp;quot;: &amp;quot;~3.0.1&amp;quot;,
            &amp;quot;jasmine-core&amp;quot;: &amp;quot;~2.6.2&amp;quot;,
            &amp;quot;jasmine-spec-reporter&amp;quot;: &amp;quot;~4.1.0&amp;quot;,
            &amp;quot;karma&amp;quot;: &amp;quot;~1.7.0&amp;quot;,
            &amp;quot;karma-chrome-launcher&amp;quot;: &amp;quot;~2.1.1&amp;quot;,
            &amp;quot;karma-cli&amp;quot;: &amp;quot;~1.0.1&amp;quot;,
            &amp;quot;karma-coverage-istanbul-reporter&amp;quot;: &amp;quot;^1.2.1&amp;quot;,
            &amp;quot;karma-jasmine&amp;quot;: &amp;quot;~1.1.0&amp;quot;,
            &amp;quot;karma-jasmine-html-reporter&amp;quot;: &amp;quot;^0.2.2&amp;quot;,
            &amp;quot;protractor&amp;quot;: &amp;quot;~5.1.2&amp;quot;,
            &amp;quot;ts-node&amp;quot;: &amp;quot;~3.0.4&amp;quot;,
            &amp;quot;tslint&amp;quot;: &amp;quot;~5.3.2&amp;quot;,
            &amp;quot;typescript&amp;quot;: &amp;quot;~2.3.3&amp;quot;
        }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I recommend to install the electron platform globaly with command:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt; npm install -g electron
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first simple manual run could be done by calling following commands (these must be run in separate terminal windows as the “ng serve” is blocking)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;gt; ng serve
    &amp;gt; electron .
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Command “ng serve” will start development server on &lt;a href=&#34;http://localhost:4200&#34;&gt;http://localhost:4200&lt;/a&gt;, you can notice the this url is used in main.js file. The &amp;ldquo;electron .&amp;rdquo; will start the electron app by executing the main.js file.&lt;/p&gt;

&lt;p&gt;You can use &lt;a href=&#34;https://www.npmjs.com/package/concurrently&#34;&gt;concurrently&lt;/a&gt; tool to run these two commands concurrently. Also it can be incorporated to package.json file as an npm script.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;npm install -g concurrently
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;${PROJECT_FOLDER}/package.json&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;quot;scripts&amp;quot;: {
        ...
        &amp;quot;electrondev&amp;quot;: &amp;quot;concurrently -k \&amp;quot;ng serve\&amp;quot; \&amp;quot;electron .\&amp;quot;&amp;quot;
    },
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;serving-static-files&#34;&gt;Serving static files&lt;/h1&gt;

&lt;p&gt;Serving angular application via development server is not very comfortable and permanent solution. Better approach is serving a static files from the build output folder (let&amp;rsquo;s call it distribution folder). The main.js file need to be changed to open the index.html file located in distribution folder of your angular application.&lt;/p&gt;

&lt;p&gt;${PROJECT_FOLDER}/main.js&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    const { app, BrowserWindow } = require(&#39;electron&#39;);
    path = require(&#39;path&#39;);
    url = require(&#39;url&#39;);
    app.on(&#39;ready&#39;, function() {
        console.log(&#39;Starting application!&#39;);
        mainWindow = new BrowserWindow({ width: 1280, height: 960 });
        
        // Change loadUrl to load index.html
        // using url and path package 
        // to format the file url
        mainWindow.loadURL(url.format({
            //__dirname is the current working dir
            pathname: path.join(__dirname, &#39;dist&#39;, &#39;index.html&#39;),
            protocol: &#39;file:&#39;,
            slashes: true
        }));
    
        // Opens dev tools
        mainWindow.webContents.openDevTools();
        mainWindow.on(&#39;closed&#39;, function() {
            mainWindow = null;
        });
    });
    app.on(&#39;window-all-closed&#39;, function() {
        app.quit();
    });
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After you open electron you will receive “Failed to load resource” error.
There is one step missing to get the change work.
&lt;img src =&#34;https://d2mxuefqeaa7sj.cloudfront.net/s_F68920300BC018EB3E1E88614B689BAD376E939D730AA4BF30888F46A4DF2F8A_1501387336733_image.png&#34;/&gt;&lt;/p&gt;

&lt;p&gt;The one small change that need to be done is in your index.html file. We need to define the base for the file as absolute but from the actual working directory like “./”. This is done in &lt;base&gt; element in head tag of index.html . After the modification you can try “electron .” in your ${PROJECT_FOLDER}&lt;/p&gt;

&lt;p&gt;${PROJECT_FOLDER}/index.html :&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;lt;!doctype html&amp;gt;
    &amp;lt;html lang=&amp;quot;en&amp;quot;&amp;gt;
    &amp;lt;head&amp;gt;
        &amp;lt;meta charset=&amp;quot;utf-8&amp;quot;&amp;gt;
        &amp;lt;title&amp;gt;Electron&amp;lt;/title&amp;gt;
        &amp;lt;!-- Change the href attribute 
        to reference to cur. working dir --&amp;gt;
        &amp;lt;base href=&amp;quot;./&amp;quot;&amp;gt;
        &amp;lt;meta name=&amp;quot;viewport&amp;quot; content=&amp;quot;width=device-width, initial-scale=1&amp;quot;&amp;gt;
        &amp;lt;link rel=&amp;quot;icon&amp;quot; type=&amp;quot;image/x-icon&amp;quot; href=&amp;quot;favicon.ico&amp;quot;&amp;gt;
    &amp;lt;/head&amp;gt;
    &amp;lt;body&amp;gt;
        &amp;lt;app-root&amp;gt;&amp;lt;/app-root&amp;gt;
    &amp;lt;/body&amp;gt;
    &amp;lt;/html&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s it. Desktop application with Angular. The same approach could be used with other JS frameworks or just pure static HTML. I was excited how easy it is.&lt;/p&gt;

&lt;p&gt;The repository with example project &lt;a href=&#34;https://github.com/sohlich/angular_on_electron&#34;&gt;https://github.com/sohlich/angular_on_electron&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;series&#34;&gt;Series:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://sohlich.github.io/post/angular_electron/&#34;&gt;Angular on Electron, part 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sohlich.github.io/post/angular_electron_2/&#34;&gt;Angular on Electron, part 2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Streaming JSON with Jackson</title>
      <link>https://sohlich.github.io/post/jackson/</link>
      <pubDate>Wed, 08 Feb 2017 20:27:44 +0100</pubDate>
      
      <guid>https://sohlich.github.io/post/jackson/</guid>
      <description>&lt;p&gt;Sometimes there is a situation, when it is more
efficient to parse the JSON in stream way.
Especially if you are dealing with huge input
or slow connection. In that case the JSON need to be read
as it comes from input part by part.
The side effect of such approach is that you are able to
read corrupted JSON arrays in some kind of comfortable way.&lt;/p&gt;

&lt;p&gt;Well known Jackson library (&lt;a href=&#34;https://github.com/FasterXML/jackson-core&#34;&gt;https://github.com/FasterXML/jackson-core&lt;/a&gt;)
provides so called stream API to handle it.
The parsing of stream is possible via
JsonParser object, which uses token approach.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;InputStream is = new FileInputStream(&amp;quot;data.json&amp;quot;);
JsonFactory factory = new JsonFactory();
JsonParser parser = factory.createJsonParser(is);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;To simplify the approach, the combination of ObjectMapper
with sequetial reading of JSON data could be used.The code of the
complete solution could be like:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public void tryParse(InputStream is) throws IOException {
		JsonFactory factory = new JsonFactory();
		JsonParser parser = factory.createJsonParser(is);
		ObjectMapper mapper = new ObjectMapper()
				.configure(DeserializationConfig.Feature.FAIL_ON_UNKNOWN_PROPERTIES,false);

		JsonToken token = parser.nextToken();
		
        	// Try find at least one object or array.
		while (!JsonToken.START_ARRAY.equals(token) &amp;amp;&amp;amp; token != null &amp;amp;&amp;amp; !JsonToken.START_OBJECT.equals(token)) {
			parser.nextToken();
		}

		// No content found
		if (token == null) {
			return;
		}

		boolean scanMore = false;

		while (true) {
			// If the first token is the start of obejct -&amp;gt;
			// the response contains only one object (no array)
			// do not try to get the first object from array.
			try {
				if (!JsonToken.START_OBJECT.equals(token) || scanMore) {
					token = parser.nextToken();
				}
				if (!JsonToken.START_OBJECT.equals(token)) {
					break;
				}
				if (token == null) {
					break;
				}

				Object node = mapper.readValue(parser, mappedClass);
				
				//YOUR CODE TO HANDLE OBJECT
				//...


				scanMore = true;
			} catch (JsonParseException e) {
				handleParseException(e);
				break;
			}
		}
	}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Nats Proxy Framework</title>
      <link>https://sohlich.github.io/post/natsproxy/</link>
      <pubDate>Sun, 28 Aug 2016 08:48:41 +0200</pubDate>
      
      <guid>https://sohlich.github.io/post/natsproxy/</guid>
      <description>

&lt;p&gt;The REST to NATS proxy project &lt;a href=&#34;http://gopkg.in/sohlich/nats-proxy.v1&#34;&gt;sohlich/nats-proxy&lt;/a&gt; is the micro framework that provides a bridge between HTTP and NATS. To introduce the problem, we first compare the HTTP and NATS communication models. The table below represents the matching of HTTP and NATS concepts and what do they provide.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;HTTP&lt;/th&gt;
&lt;th&gt;NATS&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Request/Response&lt;/td&gt;
&lt;td&gt;Request/Reply&lt;/td&gt;
&lt;td&gt;synchronous communication&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Websocket&lt;/td&gt;
&lt;td&gt;Publish/Subscribe&lt;/td&gt;
&lt;td&gt;real-time asynchronous communication&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;As you can see, the NATS provides both synchronous and asynchronous communication between clients. The synchronous communication, represented by simple Request and Response of HTTP protocol, could be matched with the Request/Reply communication model of NATS. As the documentation for &lt;a href=&#34;http://nats.io/documentation/concepts/nats-req-rep/&#34;&gt;&amp;ldquo;request reply&amp;rdquo; &lt;/a&gt; model describes: each request sent via NATS contains reply subject, to which the reply is sent. The asynchronous, let&amp;rsquo;s say real-time communication, can be represented by Websockets on HTTP side.The truth is that it is not really related to HTTP, but if we simplify it, at least the handshake is based on HTTP. For this purpose, the Publish/Subscribe model could be used.&lt;/p&gt;

&lt;p&gt;So the REST to NATS project uses this similarity between NATS and HTTP communication and tries to implement the bridge between HTTP(Websockets) and NATS in such way. The library was originally created for the purpose of migrating REST based architecture like this&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;img-responsive center-block&#34; src=&#34;https://sohlich.github.io/img/blog/natsproxy/natsproxy_rest.png&#34;&gt;&lt;/p&gt;

&lt;p&gt;into NATS messaging platform based one. But as it evolved, it started to grow into some kind of framework, that can be used for the creation of service API and seamless protocol bridging. So one of the many examples of how the system using a nats-proxy framework could look like is on the architecture below.&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;img-responsive center-block&#34; src=&#34;https://sohlich.github.io/img/blog/natsproxy/natsproxy_arch.png&#34;&gt;&lt;/p&gt;

&lt;h2 id=&#34;proxy-basics&#34;&gt;Proxy basics&lt;/h2&gt;

&lt;p&gt;As the name of the project suggests the function of the library is very similar to basic HTTP proxy. The proxy receives the HTTP request and translates it into a struct, which contains all the information from original request (URL, header, body).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Request struct {
	URL        string
	Method     string
	Header     http.Header
	Form       url.Values
	RemoteAddr string
	Body       []byte
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This struct is serialized and sent as a message through NATS via request (see &lt;a href=&#34;http://nats.io/documentation/concepts/nats-req-rep/&#34;&gt;http://nats.io/documentation/concepts/nats-req-rep/&lt;/a&gt;) to ensure synchronous processing.
The subject, to which the serialized struct is sent, is constructed from the HTTP request URL and METHOD by a very simple rule: slashes in the path are replaced by dots and the method is used as the prefix.&lt;/p&gt;

&lt;p&gt;&lt;img class=&#34;img-responsive center-block&#34; src=&#34;https://sohlich.github.io/img/blog/natsproxy/natsproxy_request.png&#34;&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Lets say we have GET request on URL &lt;code&gt;http://example.com/user/info&lt;/code&gt; so the proxy will translate this URL to  subject &lt;code&gt;GET:user.info&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The client side is subscribed to the subject &lt;code&gt;GET:user.info&lt;/code&gt;. Because of that, it receives the request and writes back the response to the reply subject. The response struct also contains the body, status and header.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;type Response struct {
	Header     http.Header
	StatusCode int
	Body       []byte
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For better picture of how it works in reality. There is a code of simple client and proxy.&lt;/p&gt;

&lt;h2 id=&#34;proxy&#34;&gt;Proxy&lt;/h2&gt;

&lt;p&gt;The proxy side implements the &lt;code&gt;http.Handler&lt;/code&gt; interface, so it can be used with built-in &lt;code&gt;http&lt;/code&gt; package as you can see in the code below. The handler does nothing special. It parses the request and translates it to custom representation which is then serialized to JSON by built in &lt;code&gt;json&lt;/code&gt; package encoder.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;import(
        &amp;quot;gopkg.in/sohlich/nats-proxy.v1&amp;quot;
        &amp;quot;net/http&amp;quot;
        &amp;quot;github.com/nats-io/nats&amp;quot;
    )

func main() {
	proxyConn, _ := nats.Connect(nats.DefaultURL)
	proxy, _ := natsproxy.NewNatsProxy(proxyConn)
	defer proxyConn.Close()
	http.ListenAndServe(&amp;quot;:8080&amp;quot;, proxy)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The proxy itself does not implement any mechanisms to apply filters before the request is passed to the proxy handler as this could be implemented by decorating the proxy handler or other similar techniques.
Because the implementation does not allow writing data to the &lt;code&gt;http.ResponseWriter&lt;/code&gt; after the handler is applied, the proxy provides &lt;code&gt;natsproxy.Hook&lt;/code&gt; interface. This hook is applied on the response before it is written to &lt;code&gt;http.ResponseWriter&lt;/code&gt;. The example bellow shows the usage of hook to translate JWT token with all user info to meaningless reference token.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;proxyHandler.AddHook(&amp;quot;.*&amp;quot;, func(r *Response) {
        // Exchange the jwt token for
        // reference token to hide user information
        jwt := r.GetHeader().Get(&amp;quot;X-Auth&amp;quot;)
        refToken := auth.GetTokenFor(jwt)
		r.GetHeader().Set(&amp;quot;X-Auth&amp;quot;, refToken)
	})
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;client&#34;&gt;Client&lt;/h2&gt;

&lt;p&gt;The client code uses the nats connection as the constructor argument, so all available options for configuring the connection are accessible. The client itself uses the asynchronous subscription to handle incoming messages, so it&amp;rsquo;s behavior similar to &lt;code&gt;http.HandlerFunc&lt;/code&gt;. The client API and internals are heavily inspired by &lt;a href=&#34;https://gin-gonic.github.io/gin/&#34;&gt;Gin Gonic&lt;/a&gt; project. The sample code shows how to use the client API.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;
import(
    &amp;quot;gopkg.in/sohlich/nats-proxy.v1&amp;quot;
    &amp;quot;net/http&amp;quot;
    &amp;quot;github.com/nats-io/nats&amp;quot;
)

func main(){
	clientConn, _ := nats.Connect(nats.DefaultURL)
	natsClient, _ := natsproxy.NewNatsClient(clientConn)
	//Subscribe to URL /user/info
	natsClient.GET(&amp;quot;/user/info&amp;quot;, func(c *natsproxy.Context) {
	   user := struct {
		    Name string
	    }{
		    &amp;quot;Alan&amp;quot;,
	    }
		c.JSON(200, user)
	})
	defer clientConn.Close()

	// Waiting for signal to close the client
	sig := make(chan os.Signal, 1)
	signal.Notify(sig, syscall.SIGINT, syscall.SIGTERM)
	fmt.Println(&amp;quot;Press Ctrl+C for exit.&amp;quot;)
	&amp;lt;-sig
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The client API naturally provides the subscription for other HTTP methods and generic subscription method. The request handler which implements &lt;code&gt;natsproxy.NatsHandler&lt;/code&gt; interface uses &lt;code&gt;natsproxy.Context&lt;/code&gt; struct which encapsulates both Request and Response and provides some useful methods to access request data and to write a response.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;//GET
natsClient.GET(&amp;quot;/user/info&amp;quot;, func(c *natsproxy.Context) {
		c.JSON(200, &amp;quot;Hello&amp;quot;)
	})

//POST
natsClient.POST(&amp;quot;/user/info&amp;quot;, func(c *natsproxy.Context) {
		c.JSON(200, &amp;quot;Hello&amp;quot;)
	})

//PUT
natsClient.PUT(&amp;quot;/user/info&amp;quot;, func(c *natsproxy.Context) {
		c.JSON(200, &amp;quot;Hello&amp;quot;)
	})

//DELETE
natsClient.DELETE(&amp;quot;/user/info&amp;quot;, func(c *natsproxy.Context) {
		c.JSON(200, &amp;quot;Hello&amp;quot;)
	})

//General method
natsClient.Subscribe(&amp;quot;HEAD&amp;quot;,&amp;quot;/user/info&amp;quot;, func(c *natsproxy.Context) {
		c.JSON(200, &amp;quot;Hello&amp;quot;)
	})

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The client also implements middleware function that provides the means of accessing the request before it is handled by the specific handler. The reason behind this feature is to provide options for security checks, logging, etc. The example shows the implementation of middleware, that logs all incoming requests.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-go&#34;&gt;natsClient.Use(func logger(c *natsproxy.Context) {
    log.Infof(&amp;quot;%s:%s from %s&amp;quot;, c.Request.Method, c.Request.URL)
})
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;The first version (v1) of the nats-proxy framework implements only HTTP Request/Response proxying.
Because it started as some kind of proof of concept, the solution is not really optimized, all the work is done on the proxy side.
Also, the serialization of structs is done by JSON encoder, which does not provide very fast serialization.
However for the purpose of bridging REST(HTTP) requests to NATS messaging platform, it&amp;rsquo;s enough to make it possible.&lt;/p&gt;

&lt;p&gt;Currently, the next version (v2) is under development.
The v2 should bring some performance improvements because the serialization is done via protocol buffers. Also, a lot of work originally done on the proxy side was moved to client(service) side.The next significant feature is the WebSocket support.&lt;/p&gt;

&lt;p&gt;If you are interested or have some ideas, see &lt;a href=&#34;https://github.com/sohlich/nats-proxy&#34;&gt;REST to NATS proxy&lt;/a&gt; project.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>